{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visualizers.labellednn import NeuralNetworkPlot\n",
    "from IPython.display import IFrame\n",
    "from Visualizers.threeDConstructor import NeuralNetworkVisualization\n",
    "from Visualizers.singleMinima import GradientDescentSimulator\n",
    "from Visualizers.multiMinima import MultiMinimaSimulator\n",
    "from Visualizers.OptimizerComparisons import MultiMinimaSimulatorAdaptive\n",
    "from Visualizers.spinningPerceptron import PerceptronPlotlyDemo\n",
    "from Visualizers.derivativeGraph import PlotlySurfaceWithGradient\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **A Comprehensive Breakdown of Neural Networks with Reasoning Behind My Own Design Choices for my Neural Network**\n",
    "\n",
    "Author: Patrick Erickson\n",
    "\n",
    "---\n",
    "\n",
    "## Abstract\n",
    "---\n",
    "\n",
    "Neural Networks have been gaining a lot of traction in the world as of recent, with the rise of giant models such as Chat-GPT and other LLMs. While the complexity of these giant AI models can not be explained by neural networks alone, they make up a core part of what makes them function. Furthermore, there are thousands of other types of models that use neural networks in their architecture to help them make predictions. In this document, I will be detailing the reason and intuition behind neural networks, the math behind them, including how to forward pass, activation functions, regularization techniques, and backpropagation (if you don't know what these mean, don't worry. We'll cover it!), and more complex stuff such as optimization functions. Lastly, I will go over an in-depth analysis on my own Neural Network's architecture so you can see my own intuitions behind the construction of one, from scratch without the use of popular libraries such as TensorFlow, PyTorch, and JAX. This article does assume, however, that you have a basic understanding of classification and regression, derivatives, and the derivative chain rule. I also expect that you understand how matrix multiplication, addition, and subtraction works. For the scope of this document, we will not be delving into Convolutional Heads or Time Series.\n",
    "\n",
    "### A Brief History of Neural Networks: The Perceptron\n",
    "The birth of the Neural Network had much humbler beginnings than the giant models we see today. [Frank Rosenblatt](https://en.wikipedia.org/wiki/Frank_Rosenblatt), at the Cornell Aeronautical Laboratory, had constructed something called a single layer perceptron simulated on an IBM 704 in 1957. This \"perceptron\" was made to simulate an individual neuron within the human brain, which either fires or doesn't fire based on the input it's given. \n",
    "\n",
    "For example, let's say we know the following about someone:\n",
    "  - Income\n",
    "  - Properties Owned\n",
    "\n",
    "and we we want to predict if that person is rich or not rich (we will use 0 for not rich and 1 for rich). Our perceptron will look as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptronPlot = NeuralNetworkPlot(\n",
    "    title=\"Perceptron\",\n",
    "    nodes_per_layer=[2,1,1],\n",
    "    label_arrows=True,\n",
    "    arrow_label_overrides={(0,0,0):\"Income\",(0,1,0):\"Properties Owned\",(1,0,0):\"Are they Rich? (0/1)\"}\n",
    ")\n",
    "perceptronPlot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the intuition behind this is that there is some correlation between the sizes of the features and the final output of being rich or not. Fer example, the income and the number of properties owned aren't over a certain threshold, we would print 0, for being not rich. Likewise, if income and and property value aren over this threshold, we then predict 1 (rich). More specifically, the algorithm looks at all of the points it misclassifies and then performs an operation to move the hyperplane to fix that misclassification. This algorithm continues to do this until all points are satisfied. We can visualize how the perceptron works with the following simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfectSep = PerceptronPlotlyDemo(\n",
    "    title=\"Perceptron Simulation\",\n",
    "    n_points=100,\n",
    "    max_updates=50,\n",
    "    seed=42,\n",
    "    linearlySeperable=0\n",
    ")\n",
    "perfectSep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations of the Perceptron\n",
    "As you can see, we slowly \"fixed\" the classifying line until all the \"Rich\" points are on one side of the line while all of the \"Not Rich\" points are on the other side of the line. We can therefore \"linearly seperate\" the data to make our predictions, which is the whole basis on how perceptrons work. However, what if the data isn't linearly seperable? For example, there could be some people who are considered \"rich\" who may only have one property, but that one property is a skyscraper in Manhattan worth billions. Our perceptron doesn't have this information, and we may not necessarily know this information to be able to put it into the perceptron. This \"unexplained data\" may cause our dataset to look more like this simulation, and is more analagous to the real world:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfectSep = PerceptronPlotlyDemo(\n",
    "    title=\"Perceptron Simulation For non Linearly-Seperable Data\",\n",
    "    n_points=100,\n",
    "    max_updates=200,\n",
    "    seed=42,\n",
    "    linearlySeperable=1\n",
    ")\n",
    "perfectSep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron will have trouble classifying it, and the algorithm will never stop (converge), since there will always be some extra \"movement\" that can be made to try and fix the errors in the loss function. This issue only gets worse for datasets where linear seperability is borderline impossible. However, we can see that the data is still approximately linearly seperable, which allows us to be able to use methods such as logistic regression and other machine learning techniques will do a pretty good job of predicting the overall overall dataset, especially in the case we just described. But what about for data that isn't even remotely seperable? Let's look at the following example:\n",
    "\n",
    "### Further Limitations of Perceptron with XOR\n",
    "\n",
    "Assume we want to predict whether a customer would buy a product based on whether or not they visit the online and physical store of a specific company to review a product. It can be said that if a customer does not visit the online or real store, then the customer will not buy the product, because they are not interested. Likewise, a customer will most likely not walk out with anything if they visit both the online and real store, because they are currently assessing their options and they will not make a hasty decision on buying the product. However, if a customer visits the online store but not the real store, the customer may be more likely to buy it because they may think it's cheap and convenient. Likewise, a customer might be more enticed to buy a product if they physically saw it at the real store, but did not think to compare online, since the enticing prospect of buying and immediately having it is really high. We can model this problem with the following table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XOR = np.empty((4,2), dtype='U10')\n",
    "XOR[0,0] = \"No\"\n",
    "XOR[0,1] = \"No\"\n",
    "XOR[1,0] = \"No\"\n",
    "XOR[1,1] = \"Yes\"\n",
    "XOR[2,0] = \"Yes\"\n",
    "XOR[2,1] = \"No\"\n",
    "XOR[3,0] = \"Yes\"\n",
    "XOR[3,1] = \"Yes\"\n",
    "\n",
    "labels = np.array([\"No\",\"Yes\",\"Yes\",\"No\"])\n",
    "XOR = np.c_[XOR,labels]\n",
    "columns = [\"Visted Store\", \"Visted Online\", \"Bought Item\"]\n",
    "df = pd.DataFrame(XOR,columns=columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a classic XOR problem, and even logistic regression and other classification methods perform poorly on this kind of data without any explicit feature engineering. Our perceptron will also suffer the same fate. The following is a simulation of different datapoints based on the company predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xorProblem = PerceptronPlotlyDemo(\n",
    "    title=\"Perceptron Simulation For non Linearly-Seperable Data\",\n",
    "    n_points=100,\n",
    "    max_updates=200,\n",
    "    redName=\"Didn't Buy Item\",\n",
    "    blueName=\"Bought Item\",\n",
    "    seed=42,\n",
    "    linearlySeperable=2\n",
    ")\n",
    "xorProblem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected, the perceptron performs extremely poorly. This phenomenon itself led to one of the biggest AI winters ever since the conception of the perceptron, slowing AI research to a near standstill for 20 years. However, this obviously does not pertain to today, as we have figured out a clever workaround for this issue. This, along with stochastic nature of the perceptron algorithm, did not specify loss efficiently, and would therefore oscillate with no real solution. In Layman's terms, the perceptron had no \"confidence\" in its decisions, based on the distance a point was from the classifying boundary.\n",
    "\n",
    "## Introduction to Neural Networks\n",
    "---\n",
    "\n",
    "\n",
    "The Universal approximation theorem ultimately states that combining multiple linear segments into one unified classification output can approximate any function, given enough perceptrons. This groundbreaking revelation in 1989 spurred the idea of stacking and adding up the effects of all of the inputs together in one \"layer\" to be able to finally classify non-linear decision boundaries, like the XOR problem we had described above. The idea of using the \"confidence method\" as I had described as an output head had also given rise to solving the issue of the perceptron jumping around everywhere and never converging. This new misclassification minimization required gradient descent, and round this time as well. a new algorithm called backpropagation was developed. Backpropagation efficiently calculates the chained derivatives of the hidden layer for gradient descent, so now the perceptrons weights could be tuned in a manner to mimimize the confidence misclassifications, or in other words loss. Lastly, breakthroughs in functions (called **activation functions**) that could be used to replace the non-differentiable, 0-derivative step function (-1 if wrong, +1 if right) the perceptron was using were also introduced, which was the final piece in creating a differentiable network able to be trained to minimize the loss. All of these together created the framework for the Artificial Neural Network.\n",
    "\n",
    "### Types of activation functions\n",
    "\n",
    " Some of the activation functions mentioned are: \n",
    "   - ReLU (Rectified Linear Unit), a function x that is 0 when $x\\leq0$\n",
    "   - $\\tanh$, used to create some value in between -1 and 1\n",
    "   - sigmoid, usually used to model some probability, giving a value of 0 to 1.\n",
    "\n",
    " They can be defined as the following, with their derivatives:\n",
    "\n",
    "$$\n",
    "\\operatorname{ReLU}(x) = \\begin{cases}\n",
    "x, & \\text{if } x \\geq 0, \\\\\n",
    "0, & \\text{if } x < 0.\n",
    "\\end{cases}\n",
    "$$\n",
    "$$\n",
    "\\operatorname{ReLU'}(x) = \\begin{cases}\n",
    "1, & \\text{if } x \\geq 0, \\\\\n",
    "0, & \\text{if } x < 0.\n",
    "\\end{cases}\n",
    "$$\n",
    "$$\n",
    "\\tanh(x) = \\frac{e^x-e^{-x}}{e^x+e^{-x}} \n",
    "$$\n",
    "$$\n",
    "\\tanh'(x) = 1 - (\\frac{e^x-e^{-x}}{e^x+e^{-x}})^2 = 1 - \\tanh^2(x)\n",
    "$$\n",
    "$$\n",
    "sigmoid(x) = \\frac{1}{1+e^{-x}} \\text{. Note that this is commonly denoted as } \\sigma(x)\n",
    "$$\n",
    "$$\n",
    "sigmoid'(x) = 1 - \\frac{e^{-x}}{(1+e^{-x})^2} = (\\frac{1}{1+e^{-x}})(1-\\frac{1}{1+e^{-x}}) = \\sigma(x)(1-\\sigma(x))\n",
    "$$\n",
    "  - **Note:** For sigmoid, due to the nature of the loss function it is usually good practice to ensure that values never go past ($1*10^{-8},1-1*10^{-8}$). This is called clipping, and ensures your super confident features don't diverge to infinity.\n",
    "\n",
    "All of these can be used to replace the perceptron loss. **However, do note that for stable convergence it is highly recommended that you only use one type of activation and it's respective derivative for your entire network. This guarantees better convergence, and I tested this. Mixing activations just suck, you can try it yourself with my own [custom-implemented neural network](https://github.com/PatrickErickson4/FullyModularNumpyArtificialNeuralNetwork).** There are also many other types of activations, but for the sake of this demonstration, we will be working with these activations. If you want to get more into the math and look at the graphs for these functions, you can find it [here](####Derivatives-for-the-activation-functions). \n",
    "\n",
    "  - **Fun Fact:** Something interesting of note is that ReLU is piecewise, so you might be wondering how this is differentiable for backpropagation. Well, the secret lies in being able to see which features were activated on unactivated by relu. Since we define that if $x=0$, then the derivative will also be zero, we fix the nondifferentiability issue. Secondly, x will just be 1, which preserves information. Meanwhile the step function is either -1 or 1, with nothing with respect to x. This gives us 0 for the entire function, giving us no meaningful information for backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions\n",
    "\n",
    "There are also loss functions that assign some sort of non-discrete confidence of each prediction, in order to continue with the theme of differentiability for backpropagation. These are found at the end of the Neural Networks, commonly referred to as the \"head\". It is common to use softmax for classification problems. Softmax assignes a probability of confidence to each of the different categories for our problem, which we can then pick the highest in order to classify our problem. For example, if we have 3 categories, those being good, neutral, or bad, the number 1 will be split across all 3 of these categories based on the confidence for each prediction. There is also Mean Squared Error (MSE) for regression, which is the exact same formula used in that of linear regression. The following loss functions have the respective formulas, derivatives, and a reported loss, generally shown to the user when training:\n",
    "\n",
    "**Classification:**\n",
    "$$softmax \\text{ for a single sample } p_i = \\frac{e^{x_i}}{\\sum_{j=1, i\\in K}^Ke^{x_j}}. $$\n",
    "In other words, the probability of every category for 1 sample in the dataset, and $p_i$ is analagous to the softmax function.\n",
    "$$ \\text{categorical cross entropy loss }= -\\frac{1}{n}\\sum_{i=1}^n \\hat{y_i}\\log(p_i)\\text{. }$$ \n",
    "In other words, the amount the prediction deviated from the actual for the entire dataset.\n",
    "$$softmax' \\text{ for a single sample } = (p_i-\\hat{y_i})\\text{. }$$\n",
    "In other words, how much we need to change our prediction by to fix the error.\n",
    "\n",
    "\n",
    "**Regression:**\n",
    "$$MSE \\text{ prediction for a single sample }= \\hat{y_i}\\text{. }$$\n",
    "In other words, the square of how much one variable is on the y axis away from our predicted best fit line.\n",
    "$$MSE \\text{ loss }= -\\frac{1}{n}\\sum_{i=1}^n (\\hat{y_i}-\\bar{y_i})^2\\text{. }$$ \n",
    "In other words, the amount the prediction deviated from the actual for the entire dataset.\n",
    "$$MSE' \\text{ for a single sample }= \\hat{y_i}-\\bar{y_i}\\text{. }$$\n",
    "In other words, how much we need to change our prediction by to fix the error.\n",
    "\n",
    "the following is a key for all of the variables:\n",
    "  - $p_i$ is the softmax function\n",
    "  - $\\hat{y_i}$ is the true value that we are trying to predict for the label $i$ in our dataset.\n",
    "  - $\\bar{y_i}$ is the value we predicted with our model\n",
    "  - $x_i$ are the values we get from the last layer.\n",
    "  - $\\frac{1}{n}\\sum_{i=1}^n$ means the \"mean\" of the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For calculating the loss, it is much easier to think of it for every sample. We can calculate these then average the losses across all samples to get the middle loss value, which is generally shown to the client training a neural network. These equations are all based in fundamental statistics and the log likelihood to be able to find this total versus expected loss. If you wish to learn more about the math and derivations behind these, they can be found [here](####Statistical-Likelihoods-and-Derivatives-of-Loss-Functions). Like the activation functions, there are also many different kinds of loss functions, especially for regression, but for the time being we will be sticking with these, as they are the most common. While you have most likely heard of mean squared error, you may not have heard of softmax. Let me explain it briefly:\n",
    "\n",
    "#### What is softmax?\n",
    "**Softmax turns all of your categories into probabilities of being picked.** Suppose you want to predict 10 different numbers, 0 through 9, from a dataset of images like the [MNIST Handwritten Digits Dataset](http://yann.lecun.com/exdb/mnist/). Let's say we want to predict the number 3. The idea is that the number produced for our model for the category of 3 will be a lot higher than the rest of the categories. What softmax does is it takes into account the values going into that specific category and divides it by the values of all the other categories to get a probability distribution for each category. If we look at the example, we can calculate the probability of us correctly picking 3 as such:\n",
    "$$\\frac{e^{x_3}}{e^{x_0}+e^{x_1}+e^{x_2}+e^{x_3}+e^{x_4}+e^{x_5}+e^{x_6}+e^{x_7}+e^{x_8}+e^{x_9}}$$\n",
    "notice that this is the same as softmax we described as above, but expanded for the scope of our problem:\n",
    "$$p_3 = \\frac{e^{x_3}}{\\sum_{i=0, 3\\in \\text{ the set of integers from 0-9 }}^9e^{x_i}}$$\n",
    "In other words, $K$ represents all categories, and each x will be the corresponding specific value of the category, where the bigger number for a specific category yields a higher probability. If our model were correct, our probability distribution would look something like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(100)\n",
    "base_logits = np.array([8, 8, 8, 10, 3, 7, 8, 2, 9, 8])\n",
    "noise = np.random.uniform(-0.5, 0.5, size=base_logits.shape)\n",
    "noisy_logits = base_logits + noise\n",
    "if np.max(np.delete(noisy_logits, 3)) >= noisy_logits[3]:\n",
    "    noisy_logits[3] = np.max(np.delete(noisy_logits, 3)) + 0.1\n",
    "exp_logits = np.exp(noisy_logits)\n",
    "probs = exp_logits / np.sum(exp_logits)\n",
    "digits = np.arange(10)\n",
    "colors = ['red' if i == 3 else 'skyblue' for i in range(10)]\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "bars = ax.barh(digits, probs, color=colors)\n",
    "for bar, prob in zip(bars, probs):\n",
    "    width = bar.get_width()\n",
    "    ax.text(width + 0.005, bar.get_y() + bar.get_height()/2, f'{prob:.3f}', va='center')\n",
    "\n",
    "ax.set_yticks(digits)\n",
    "ax.set_yticklabels(digits)\n",
    "ax.set_title('Probability distribution for 10 Categories')\n",
    "plt.figtext(0.5, 0.0, '3 has the highest probability, so we pick 3.', color='red', ha='center', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model is \"this confident\" in predicting a 3. If certain probabilities are closer, that means our model is less confident in our prediction. Using this, we can classify many different categories. Modern architectures sometimes have thousands of these categories for image recognition, in order to accomplish things like object detection. If you want to see its connections to the sigmoid function and what makes it different from the sigmoid function, click [here](####Softmax-reduction-into-sigmoid).\n",
    "\n",
    "If instead all of these equations may look complicated, I promise it is as easy as just putting the function in the correct part of the formula. The derivations are all here for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Neural Networks\n",
    "---\n",
    "\n",
    "Going back to our [**original shopping problem**](###Further-Limitations-of-Perceptron-with-XOR),  assume the following features are going to the shop ($x_1$) in store or online or not ($x_2$). We are going to simulate the following neural network, in order to see how a perceptron with a softmax head will perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 1, 2, 2],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={}  \n",
    ")\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this is almost exactly like the perceptron, but now we have a softmax output. **For the purpose of our example, note that there is an extra node that does not have any weights tied to it: it simply performs softmax**. When you are ready, press play on the following simulation, and see how the decision boundary changes on the graph. Stop it when the graph no longer seems to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(src=\"https://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.1&regularizationRate=0&noise=0&networkShape=1&seed=0.58130&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\",width=800,height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Based on the tensorflow playground, it is still impossible to linearly seperate the data. Let's try a different approach.  Using the Universal Approximation Theorem, we will construct the following neural network with 4 nodes in the hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 4, 2, 2],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={}  # provide any overrides as \n",
    ")\n",
    "\n",
    "# Display the plot.\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we try our simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(src='https://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.1&regularizationRate=0&noise=0&networkShape=4&seed=0.58130&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false',width=800,height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how with four different linear combinators, we can create four different \"segments\" and finally solve the issue that has plagued AI researchers during the 70's and 80's.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The need for layers\n",
    "\n",
    "While the Universal Approximation theorem states that you can approximate any function $f(x)$ given the appropriate amount of nodes, this does not necessarily mean we should make  a single layer with this sufficient amount of nodes. By breaking each number of nodes up into seperate layers, we are able to compound on the features learned by each layer to arrived at a better gerneralization. We can see this motivation with the following architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 8, 2, 2],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={}\n",
    ")\n",
    "\n",
    "# Display the plot.\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this represented in Tensorflow. We will try to classify a spiral dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(src='https://playground.tensorflow.org/#activation=relu&regularization=L2&batchSize=10&dataset=spiral&regDataset=reg-plane&learningRate=0.1&regularizationRate=0.003&noise=0&networkShape=8&seed=0.30700&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false',width=800,height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the example, you can see the model struggle to correctly seperate the feature space. However, let's define a different architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 6,6, 2, 2],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={}\n",
    ")\n",
    "\n",
    "# Display the plot.\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this performs in the playground on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(src='https://playground.tensorflow.org/#activation=relu&regularization=L2&batchSize=10&dataset=spiral&regDataset=reg-plane&learningRate=0.1&regularizationRate=0.003&noise=0&networkShape=6,6&seed=0.30700&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false',width=800,height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the first layer learns bigger, more simple features, which are then fed into the second layer, where features are broken down and refined. As a result, we get a much better generalization than the 8 node example we had shown previously. This is the core idea behind deep learning: we can approximate almost any function, given enough layers and nodes. We have since learned how to numerically represent words and pictures, and we can therefore generalize even more complex ideas such as this. LLM's like ChatGPT and image generators such as DALL-E build off of this.\n",
    "\n",
    "  - **Fun Fact:** There is a theory in statistics that states that the best models are the simplest, referred to as Ockham's Razor. Neural Networks are thought to have been unscalable because of this. However, do you see how some of these nodes you see how some the nodes aren't used at all? The idea behind sparsification: that a neural network only trains the nodes it needs to, and you can effectively prune these other nodes. The idea behind it therefore is that the more nodes you add, the more likely you are to find a solution that is really good at approximating something, because there are more routes that weights can travel through. Despite this, your model can still overfit if you have too many nodes, so keep that in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thinking in Matrices: The Math Behind These Networks\n",
    "---\n",
    "\n",
    "Knowing the intuition behind why these neural networks are used, we can finally delve into the math that makes them work. Based on all of the connections for the neural network, we can see that each weight, being fully connected, can form a matrix of values. Let's look at out previous example, focusing on the blue arrow highlighting the area of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 4, 2, 2],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={},\n",
    "    special_inter_layer_arrow_color=\"blue\",\n",
    "    special_inter_layer_arrow_target_layer=1\n",
    ")\n",
    "\n",
    "# Display the plot.\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that $x_1$ connects to all four nodes, as does $x_2$. This means that there will be 8 total arrows, which matches with our diagram. Each one of these white arrows for represent some weight to multiply our input from the previous layer by. The corresponding weight matrix can be represented as such:\n",
    "\n",
    "$$\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_{1,1}^{(1)} & w_{1,2}^{(1)} \\\\[0.5em]\n",
    "w_{2,1}^{(1)} & w_{2,2}^{(1)} \\\\[0.5em]\n",
    "w_{3,1}^{(1)} & w_{3,2}^{(1)} \\\\[0.5em]\n",
    "w_{4,1}^{(1)} & w_{4,2}^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right)\n",
    "$$\n",
    "\n",
    "Where every weight has the following properties:\n",
    "$$w_{i\\text{ , }j}^{(\\ell)} $$\n",
    "\n",
    "Think of this term as any single arrow in your neural network, where the subscripts and superscripts tell us which arrow it is. Each arrow will have some weight, which will be some number.\n",
    "  - $w$ simply means weight number (the value we multiply our previous inputs by\n",
    "  - $i$ specifies which node in the layer it is going to \n",
    "  - $j$ specifies which node from the previous layer the weight is coming from\n",
    "  - $\\ell$ specifies the layer we are trying to calculate the weights for. For example, $\\ell=1$ for this particular weight matrix.\n",
    "  - if we drop the subscript $j$, that means we are talking about a particular node in the layer\n",
    "  - if we drop both subscripts and just have a capital $W^{(\\ell)}$, this means we are talking about all arrows pointing into the LAYER, which means the **entire weight matrix**.\n",
    "  - Any Weight Matrix feeding into a layer will have the dimensions (nodes of the current layer) x (nodes/features of the previous layer). In other words, $dim(W^{(\\ell)}) = \\ell\\text{ x }(\\ell-1)$\n",
    "\n",
    "Up until now, we have also been simplifying the neural network for visualization purposes. In reality, Neural Networks have a bias for every layer that looks something like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 4, 2, 2],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={},\n",
    "    special_inter_layer_arrow_color=\"blue\",\n",
    "    special_inter_layer_arrow_target_layer=1,\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "# Display the plot.\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for this bias term is to ensure that some weights do not get too big to overcompensate for a poor intercept, when weights might have learned the shape already. You can imagine this with our spiral example. Imagine our weights learned a really good boundary for classifying the weight, but the whole boundary is shifted to the right. The bias accounts for this and shifts it back to its correct place. This bias term can be represented as\n",
    "$$b^{(\\ell)}_i$$\n",
    "where \n",
    "  - i is the node the bias value corresponds to\n",
    "  - $\\ell$ is the layer the bias is being used to calculate.\n",
    "  - $b^{(\\ell)}$ is the bias value for that entire layer\n",
    "  - $b_i^{(\\ell)}$ is the bias value for the $i^{th}$ node of the $\\ell^{th}$ layer\n",
    "so an individual bias for the layer we are talking about for node can be represented as\n",
    "$$b_1^{(1)}$$\n",
    "which will correspond to some single scalar number. Likewise, the bias for the entire layer we are pointing at can be represented as:\n",
    "$$\n",
    "b^{(1)} = \n",
    "\\left( \\begin{array}{cccc}\n",
    "b_{1}^{(1)} \\\\[0.5em]\n",
    "b_{2}^{(1)} \\\\[0.5em]\n",
    "b_{3}^{(1)} \\\\[0.5em]\n",
    "b_{4}^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right)\n",
    "$$\n",
    "where each subscript represents the node the bias corresponds to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting a Number: Forward Pass\n",
    "---\n",
    "\n",
    "By computing forward pass, we get a predicted value, given all of the features we are predicting with in our dataset. The final output will give what the neural networks \"thinks\" the value should be. \n",
    "\n",
    "\n",
    "Our forward pass can be though of in 4 steps:\n",
    "  - Step 1: Multiply the Weights by the inputs\n",
    "  - Step 2: add the biases\n",
    "  - step 3: apply an activation function of your choice (ReLU, tanh, sigmoid, etc.)\n",
    "These will give you the activated values for each of the next nodes.\n",
    "\n",
    "### Iteration 1: The First Layer of Weights\n",
    "\n",
    "Let's use the neural network we have described from the previous layer:\n",
    "\n",
    "\n",
    "#### Step 1\n",
    "We multiply our previous layer's input by the corresponding row gives us the next node. When we do this, we are getting some feature representation of the previous layer and using that arrows as a means to put them into the node. For example, for node one, we would have ($w_{1,1}^{(1)} \\text{  } w_{1,2}^{(1)}$), which represents all the weights (white arrows) going to a specific node. Multiplying this by the inputs $(x_1 \\text{  } x_2)$ we can compute $w_1^{(1)}x$ to get the value for node one before being activated:\n",
    "\n",
    "\n",
    "**For node 1 in layer one (the top node):**\n",
    "\n",
    "$$\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_{1,1}^{(1)} & w_{1,2}^{(1)}\n",
    "\\end{array} \\right) \n",
    "\\left( \\begin{array}{cccc}\n",
    "x_1  \\\\[0.5em]\n",
    "x_2\n",
    "\\end{array} \\right)\n",
    "=\n",
    "w_{1,1}^{(1)}x_1 + w_{1,2}^{(1)}x_2 = w_1^{(1)}x\n",
    "$$\n",
    "\n",
    "We can do the math for the entire layer by representing the multiplications in matrix form, with each subsequent node represented by its row position in the weight matrix:\n",
    "$$\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_{1,1}^{(1)} & w_{1,2}^{(1)} \\\\[0.5em]\n",
    "w_{2,1}^{(1)} & w_{2,2}^{(1)} \\\\[0.5em]\n",
    "w_{3,1}^{(1)} & w_{3,2}^{(1)} \\\\[0.5em]\n",
    "w_{4,1}^{(1)} & w_{4,2}^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) \n",
    "\\left( \\begin{array}{cccc}\n",
    "x_1  \\\\[0.5em]\n",
    "x_2\n",
    "\\end{array} \\right) = \n",
    "\\left( \\begin{array}{cccc}\n",
    "w_{1,1}^{(1)}x_1 + w_{1,2}^{(1)}x_2 \\\\[0.5em]\n",
    "w_{2,1}^{(1)}x_1 + w_{2,2}^{(1)}x_2 \\\\[0.5em]\n",
    "w_{3,1}^{(1)}x_1 + w_{3,2}^{(1)}x_2 \\\\[0.5em]\n",
    "w_{4,1}^{(1)}x_1 + w_{4,2}^{(1)}x_2 \\\\[0.5em]\n",
    "\\end{array} \\right) =\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_1^{(1)}x \\\\[0.5em]\n",
    "w_2^{(1)}x \\\\[0.5em]\n",
    "w_3^{(1)}x \\\\[0.5em]\n",
    "w_4^{(1)}x \\\\[0.5em]\n",
    "\\end{array} \\right) \n",
    "$$\n",
    "\n",
    "#### Step 2\n",
    "Let's ADD bias 1 to node 1 as such, for example:\n",
    "\n",
    "$$w_1^{(1)}x + b_1^{(1)}$$\n",
    "\n",
    "**It is important that you do not multiply the bias. Only add. This is a common mistake many people make.** As you can see, adding bias correlates to the **red arrows** coming from the diagram's input bias into the next layer. We can represent adding bias to all nodes in matrix notation: \n",
    "\n",
    "$$\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_1^{(1)}x \\\\[0.5em]\n",
    "w_2^{(1)}x \\\\[0.5em]\n",
    "w_3^{(1)}x \\\\[0.5em]\n",
    "w_4^{(1)}x \\\\[0.5em]\n",
    "\\end{array} \\right) \n",
    "+ \\left( \\begin{array}{cccc}\n",
    "b_{1}^{(1)} \\\\[0.5em]\n",
    "b_{2}^{(1)} \\\\[0.5em]\n",
    "b_{3}^{(1)} \\\\[0.5em]\n",
    "b_{4}^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) =\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_1^{(1)}x + b_{1}^{(1)} \\\\[0.5em]\n",
    "w_2^{(1)}x + b_{2}^{(1)} \\\\[0.5em]\n",
    "w_3^{(1)}x + b_{3}^{(1)}\\\\[0.5em]\n",
    "w_4^{(1)}x + b_{4}^{(1)}\\\\[0.5em]\n",
    "\\end{array} \\right) \n",
    "$$\n",
    "We will denote this matrix as $z^{(1)}$:\n",
    "$$\n",
    "z^{(1)} = \n",
    "\\left( \\begin{array}{cccc}\n",
    "z_{1}^{(1)} \\\\[0.5em]\n",
    "z_{2}^{(1)} \\\\[0.5em]\n",
    "z_{3}^{(1)} \\\\[0.5em]\n",
    "z_{4}^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) =\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_1^{(1)}x + b_{1}^{(1)} \\\\[0.5em]\n",
    "w_2^{(1)}x + b_{2}^{(1)} \\\\[0.5em]\n",
    "w_3^{(1)}x + b_{3}^{(1)}\\\\[0.5em]\n",
    "w_4^{(1)}x + b_{4}^{(1)}\\\\[0.5em]\n",
    "\\end{array} \\right) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now at this location of the graph, without activation. We need to activate it before we send our \"nodes\" to the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 4, 2, 2],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={},\n",
    "    special_inter_layer_arrow_color=\"blue\",\n",
    "    special_inter_layer_arrow_target_layer=1,\n",
    "    special_inter_layer_arrow_offset=\"node\",\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "# Display the plot.\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "Finally, we can apply an activation, that we mentioned a previously. For the sake of ease, we let $f(x)$ be any non-linear [activation function](####Types-of-activation-functions). Then we have:\n",
    "$$\n",
    "f(z^{(1)}) = \n",
    "f\\left( \\begin{array}{cccc}\n",
    "z_{1}^{(1)} \\\\[0.5em]\n",
    "z_{2}^{(1)} \\\\[0.5em]\n",
    "z_{3}^{(1)} \\\\[0.5em]\n",
    "z_{4}^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) =\n",
    "\\left( \\begin{array}{cccc}\n",
    "\\text{Node 1}^{(1)} \\\\[0.5em]\n",
    "\\text{Node 2}^{(1)} \\\\[0.5em]\n",
    "\\text{Node 3}^{(1)} \\\\[0.5em]\n",
    "\\text{Node 4}^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right)=\n",
    "\n",
    "\\left( \\begin{array}{cccc}\n",
    "a_1^{(1)} \\\\[0.5em]\n",
    "a_2^{(1)} \\\\[0.5em]\n",
    "a_3^{(1)} \\\\[0.5em]\n",
    "a_4^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) = a^{(1)}\n",
    "$$\n",
    "\n",
    "where $a$ stands for activated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would repeat this process over and over again until you reached the end of the network. Let's do the next layer, just to see what this would look like.\n",
    "### Iteration 2: The Second Layer of Weights\n",
    "If we followed the equations correctly, you will now have the values for the first hidden layer. Let's focus on this layer, as denoted by the blue arrow:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 4, 2, 2],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={},\n",
    "    special_inter_layer_arrow_color=\"blue\",\n",
    "    special_inter_layer_arrow_target_layer=2,\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "# Display the plot.\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "We multiply our nodes by the new weight matrices. Notice how this matrix multiplication forces the numbers to be in the same dimensions as the next node layer. A plus!\n",
    "\n",
    "$$\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_{1,1}^{(2)} & w_{1,2}^{(2)} & w_{1,3}^{(2)} & w_{1,4}^{(2)}\\\\[0.5em]\n",
    "w_{2,1}^{(2)} & w_{2,2}^{(2)} & w_{2,3}^{(2)} & w_{2,4}^{(2)} \\\\[0.5em]\n",
    "\\end{array} \\right) \n",
    "\\left( \\begin{array}{cccc}\n",
    "\\text{Node 1}^{(1)} \\\\[0.5em]\n",
    "\\text{Node 2}^{(1)} \\\\[0.5em]\n",
    "\\text{Node 3}^{(1)} \\\\[0.5em]\n",
    "\\text{Node 4}^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) = \n",
    "\\left( \\begin{array}{cccc}\n",
    "w_{1,1}^{(2)}a_1^{(1)} + w_{1,2}^{(2)}a_2^{(1)} + w_{1,3}^{(2)}a_3^{(1)} + w_{1,4}^{(2)}a_4^{(1)} \\\\[0.5em]\n",
    "w_{2,1}^{(2)}a_1^{(1)} + w_{2,2}^{(2)}a_2^{(1)} + w_{2,3}^{(2)}a_3^{(1)} + w_{2,4}^{(2)}a_4^{(1)}\\\\[0.5em]\n",
    "\\end{array} \\right) =\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_1^{(2)}a^{(1)} \\\\[0.5em]\n",
    "w_2^{(2)}a^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) \n",
    "$$\n",
    "**Notice the pattern here. Every row represents all of the \"arrows\" going into that node, and every \"arrow\" multiplies the previous layer's input, $a$, but some weight. When we perform the multiplication, all the the numbers correctly format to the number of nodes in the next layer!**\n",
    "Also, notice that any node $i$ in layer $\\ell$ is the same thing as $a_i^{(\\ell)}$.\n",
    "\n",
    "#### Step 2\n",
    "We now add our bias, as deonted by the red arrows on the diagram.\n",
    "$$\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_1^{(2)}a^{(1)} \\\\[0.5em]\n",
    "w_2^{(2)}a^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) \n",
    "+ \\left( \\begin{array}{cccc}\n",
    "b_{1}^{(2)} \\\\[0.5em]\n",
    "b_{2}^{(2)} \\\\[0.5em]\n",
    "\\end{array} \\right) = \n",
    "\\left( \\begin{array}{cccc}\n",
    "w_1^{(2)}a_1^{(1)} + b_{1}^{(2)} \\\\[0.5em]\n",
    "w_2^{(2)}a_1^{(1)} + b_{2}^{(2)} \\\\[0.5em]\n",
    "\\end{array} \\right) = \n",
    "\\left( \\begin{array}{cccc}\n",
    "z_1^{(2)} \\\\[0.5em]\n",
    "z_2^{(2)} \\\\[0.5em]\n",
    "\\end{array} \\right)  = z^{(2)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This puts us at this current location of the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 4, 2, 2],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={},\n",
    "    special_inter_layer_arrow_color=\"blue\",\n",
    "    special_inter_layer_arrow_target_layer=2,\n",
    "    special_inter_layer_arrow_offset=\"node\",\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "# Display the plot.\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "We can see that this is actually the last weight layer, and given that this is a classification head, we have a softmax activation. This means that\n",
    "$$f(x) = \\frac{e^{z_i}}{e^{z_1}+e^{z_2}}, \\text{ where i is whatever node we are coming from.} $$\n",
    "\n",
    "We can apply it as such:\n",
    "$$\n",
    "f(z^{(2)}) =\n",
    "f\\left( \\begin{array}{cccc}\n",
    "z_1^{(2)} \\\\[0.5em]\n",
    "z_2^{(2)} \\\\[0.5em]\n",
    "\\end{array} \\right)  = \n",
    "\\Large\\left( \\begin{array}{cccc}\n",
    "\\frac{e^{z_1^{(2)}}}{e^{z_1^{(2)}} + e^{z_2^{(2)}}} \\\\[0.5cm]\n",
    "\\frac{e^{z_2^{(2)}}}{e^{z_1^{(2)}} + e^{z_2^{(2)}}}  \\\\[0.5em]\n",
    "\\end{array} \\right) =\n",
    "\\normalsize\\left( \\begin{array}{cccc}\n",
    "a_1^{(2)} \\\\[0.5em]\n",
    "a_2^{(2)}  \\\\[0.5em]\n",
    "\\end{array} \\right) = \n",
    "a^{(2)} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 4, 2, 2],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={},\n",
    "    special_inter_layer_arrow_color=\"blue\",\n",
    "    special_inter_layer_arrow_target_layer=3,\n",
    "    special_inter_layer_arrow_offset=\"node\",\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "# Display the plot.\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now finished forward pass!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Forward pass: What if we were doing a regression problem?\n",
    "\n",
    "If we were doing regression, our neural network will look more like this, as we are predicting some numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 4, 1, 1],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={},\n",
    "    special_inter_layer_arrow_color=\"blue\",\n",
    "    special_inter_layer_arrow_target_layer=1,\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "# Display the plot.\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration 1: \n",
    "This would be exactly the same as the previous problem:\n",
    "#### Step 1:\n",
    "$$\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_{1,1}^{(1)} & w_{1,2}^{(1)} \\\\[0.5em]\n",
    "w_{2,1}^{(1)} & w_{2,2}^{(1)} \\\\[0.5em]\n",
    "w_{3,1}^{(1)} & w_{3,2}^{(1)} \\\\[0.5em]\n",
    "w_{4,1}^{(1)} & w_{4,2}^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) \n",
    "\\left( \\begin{array}{cccc}\n",
    "x_1  \\\\[0.5em]\n",
    "x_2\n",
    "\\end{array} \\right) = \n",
    "\\left( \\begin{array}{cccc}\n",
    "w_{1,1}^{(1)}x_1 + w_{1,2}^{(1)}x_2 \\\\[0.5em]\n",
    "w_{2,1}^{(1)}x_1 + w_{2,2}^{(1)}x_2 \\\\[0.5em]\n",
    "w_{3,1}^{(1)}x_1 + w_{3,2}^{(1)}x_2 \\\\[0.5em]\n",
    "w_{4,1}^{(1)}x_1 + w_{4,2}^{(1)}x_2 \\\\[0.5em]\n",
    "\\end{array} \\right) =\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_1^{(1)}x \\\\[0.5em]\n",
    "w_2^{(1)}x \\\\[0.5em]\n",
    "w_3^{(1)}x \\\\[0.5em]\n",
    "w_4^{(1)}x \\\\[0.5em]\n",
    "\\end{array} \\right) \n",
    "$$\n",
    "**Note:** $W^{(1)}$ has dimensions $4 \\text{ x } 2$ because the next layer has 4 nodes and the previous layer had 2 nodes/features.\n",
    "\n",
    "#### Step 2:\n",
    "$$\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_1^{(1)}x \\\\[0.5em]\n",
    "w_2^{(1)}x \\\\[0.5em]\n",
    "w_3^{(1)}x \\\\[0.5em]\n",
    "w_4^{(1)}x \\\\[0.5em]\n",
    "\\end{array} \\right) \n",
    "+ \\left( \\begin{array}{cccc}\n",
    "b_{1}^{(1)} \\\\[0.5em]\n",
    "b_{2}^{(1)} \\\\[0.5em]\n",
    "b_{3}^{(1)} \\\\[0.5em]\n",
    "b_{4}^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) =\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_1^{(1)}x + b_{1}^{(1)} \\\\[0.5em]\n",
    "w_2^{(1)}x + b_{2}^{(1)} \\\\[0.5em]\n",
    "w_3^{(1)}x + b_{3}^{(1)}\\\\[0.5em]\n",
    "w_4^{(1)}x + b_{4}^{(1)}\\\\[0.5em]\n",
    "\\end{array} \\right) =\n",
    "\\left( \\begin{array}{cccc}\n",
    "z_{1}^{(1)} \\\\[0.5em]\n",
    "z_{2}^{(1)} \\\\[0.5em]\n",
    "z_{3}^{(1)} \\\\[0.5em]\n",
    "z_{4}^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) \n",
    " =z^{(1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now in this portion of our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 4, 1, 1],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={},\n",
    "    special_inter_layer_arrow_color=\"blue\",\n",
    "    special_inter_layer_arrow_target_layer=1,\n",
    "    special_inter_layer_arrow_offset=\"node\",\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "# Display the plot.\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3:\n",
    "We now activate our nodes, just like we did previously.\n",
    "$$\n",
    "f(z^{(1)}) = \n",
    "f\\left( \\begin{array}{cccc}\n",
    "z_{1}^{(1)} \\\\[0.5em]\n",
    "z_{2}^{(1)} \\\\[0.5em]\n",
    "z_{3}^{(1)} \\\\[0.5em]\n",
    "z_{4}^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) =\n",
    "\\left( \\begin{array}{cccc}\n",
    "\\text{Node 1}^{(1)} \\\\[0.5em]\n",
    "\\text{Node 2}^{(1)} \\\\[0.5em]\n",
    "\\text{Node 3}^{(1)} \\\\[0.5em]\n",
    "\\text{Node 4}^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right)=\n",
    "\n",
    "\\left( \\begin{array}{cccc}\n",
    "a_1^{(1)} \\\\[0.5em]\n",
    "a_2^{(1)} \\\\[0.5em]\n",
    "a_3^{(1)} \\\\[0.5em]\n",
    "a_4^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) = a^{(1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now here in our neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 4, 1, 1],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={},\n",
    "    special_inter_layer_arrow_color=\"blue\",\n",
    "    special_inter_layer_arrow_target_layer=2,\n",
    "    special_inter_layer_arrow_offset=\"layer\",\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "# Display the plot.\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration 2:\n",
    "\n",
    "This is where things get to be a little different. Since we are only predicting one numerical value, we only have one output node. \n",
    "\n",
    "  - **Note:** It is possible to have multiple nodes for regression. What this would mean is we are predicting multiple values at onces. For example, if we have house size, lot size, and the numnber of bathroom as our input (x1,x2,x3), we  could have 2 regression heads:\n",
    "    - One predicts house price (y1)\n",
    "    - One predicts the number of bedrooms (y2)\n",
    "  - This effectively predicting 2 values at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1:\n",
    "Multiply our weights by the nodes:\n",
    "\n",
    "$$\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_{1,1}^{(2)} & w_{1,2}^{(2)} & w_{1,3}^{(2)} & w_{1,4}^{(2)}\\\\[0.5em]\n",
    "\\end{array} \\right) \n",
    "\\left( \\begin{array}{cccc}\n",
    "\\text{Node 1}^{(1)} \\\\[0.5em]\n",
    "\\text{Node 2}^{(1)} \\\\[0.5em]\n",
    "\\text{Node 3}^{(1)} \\\\[0.5em]\n",
    "\\text{Node 4}^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) = \n",
    "\\left( \\begin{array}{cccc}\n",
    "w_{1,1}^{(2)}a_1^{(1)} + w_{1,2}^{(2)}a_2^{(1)} + w_{1,3}^{(2)}a_3^{(1)} + w_{1,4}^{(2)}a_4^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) =\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_1^{(2)}a^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we only have 1 node in the next layer, our node can be represented in a 1x1 matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2:\n",
    "Add our bias:\n",
    "\n",
    "$$\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_1^{(2)}a^{(1)} \\\\[0.5em]\n",
    "\\end{array} \\right) \n",
    "+ \\left( \\begin{array}{cccc}\n",
    "b_{1}^{(2)} \\\\[0.5em]\n",
    "\\end{array} \\right) = \n",
    "\\left( \\begin{array}{cccc}\n",
    "w_1^{(2)}a_1^{(1)} + b_{1}^{(2)} \\\\[0.5em]\n",
    "\\end{array} \\right) = \n",
    "\\left( \\begin{array}{cccc}\n",
    "z_1^{(2)} \\\\[0.5em]\n",
    "\\end{array} \\right)  = z^{(2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now in the following portion of out network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 4, 1, 1],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={},\n",
    "    special_inter_layer_arrow_color=\"blue\",\n",
    "    special_inter_layer_arrow_target_layer=2,\n",
    "    special_inter_layer_arrow_offset=\"node\",\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "# Display the plot.\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: \n",
    "\n",
    "We finish our forward pass using the regression activation. This means the layer is just linear, so we dont need to apply anything, we already have a numeric number! This means that the activation for this layer is just\n",
    "$$\n",
    "f(z^{(2)}) =\n",
    "f\\left( \\begin{array}{cccc}\n",
    "z^{(2)} \\\\[0.5em]\n",
    "\\end{array} \\right)  =\n",
    "\\left( \\begin{array}{cccc}\n",
    "z^{(2)} \\\\[0.5em]\n",
    "\\end{array} \\right) =\n",
    "\\normalsize\\left( \\begin{array}{cccc}\n",
    "a^{(2)} \\\\[0.5em]\n",
    "\\end{array} \\right) = \n",
    "a^{(2)} \n",
    "$$\n",
    "This puts us here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 4, 1, 1],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={},\n",
    "    special_inter_layer_arrow_color=\"blue\",\n",
    "    special_inter_layer_arrow_target_layer=3,\n",
    "    special_inter_layer_arrow_offset=\"node\",\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "# Display the plot.\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are at our output layer, this is actually just the output itself. This concludes forward pass through the entire network. If you wish to have more practice, I recommend asking ChatGPT for small neural networks to feed forward through. Then ask if you get it right.\n",
    "\n",
    "### Final Forward Pass Algorithm\n",
    "In conclusion, each forward pass for the nodes in layer l can be can be summed up to the following Equation:\n",
    "\n",
    "$$\\Large a^{(\\ell)} = f(W^{(\\ell)}\\cdot a^{(\\ell-1)} + b^{\\ell})$$\n",
    "\n",
    "where\n",
    "  - $f(x)$ is the [activation function](##Introduction-to-Neural-Networks)\n",
    "  - $a^{(\\ell-1)}$ is the previous layer nodes, which I have shown to be the matrix $(\\text{Node 1}^{(1)}, \\text{Node 2}^{(1)},\\cdots)$ when we were computing the final output, for example (Iteration 2)\n",
    "  - $W^{(\\ell)}$ is the weight matrix for that layer\n",
    "  - $b^{\\ell}$ is the bias for that layer\n",
    "  - $\\cdot$ is a matrix multiplication\n",
    "  - $a^{(1)}$ is always one sample in your dataset (a single row of the dataset). It has d \"nodes\" (number of columns (features), without the classification labels)\n",
    "\n",
    "Using this, you should effectively be able to calculate the \"predictions\" a neural network makes, depending on the input feature given for **one sample in a dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making our Models Learn: Backpropagation\n",
    "\n",
    "---\n",
    "\n",
    "We have covered how to predict a number with our neural network. However, if our model doesn't learn, how will it ever predict anything correctly? This is why we have to slowly \"tune\" our model so that it's weights will correctly predict what we want it to. We do this by using gradients to move in the direction that reduces this loss as much as possible.\n",
    "\n",
    "### What are Gradients?\n",
    "\n",
    "If you have every taken a calculus class before, you know what a derivative is: the change in a function at any given point f(x). The difference between derivatives and gradients lies in the fact that a gradient can be taken with respect to multiple variables, with their partial derivatives. This gradient is a **vector** of derivatives that not only tell you the magnitude of change, but also the **direction** of greatest increase. This is really useful, because most problems in machine learning are never just a single variable. Let's see an example:\n",
    "\n",
    "Assume we have the function\n",
    "$$f(x,y) = x^2+y^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_obj = PlotlySurfaceWithGradient(title=\"f(x,y)=x^2+y^2\")\n",
    "plot_obj()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we take the gradient at point (0.2,0.2):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_obj = PlotlySurfaceWithGradient(title=\"Gradient at point (.2,.2)\")\n",
    "plot_obj((-.2,.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the gradient at (.5,.5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_obj = PlotlySurfaceWithGradient(title=\"Gradient at point (.5,.5)\")\n",
    "plot_obj((-.5,.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how much bigger the arrow is. If we flip this around this can correspond to how \"steep\" the function is.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_obj = PlotlySurfaceWithGradient(title=\"Negative Gradient at point (.5,.5)\",flip=True)\n",
    "plot_obj((-.5,.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " But how does this relate to training our model?\n",
    " \n",
    "### Minimizing Loss with Gradients: Gradient Descent\n",
    "\n",
    "We had shown earlier the different loss fucntions we use for a neural network. If we were to review them again, we see that that we have the following loss functions:\n",
    "\n",
    "**Classification:**\n",
    "$$\\text{ categorical cross entropy loss }= -\\frac{1}{n}\\sum_{i=1}^n \\hat{y_i}\\log(p_i)\\text{. }$$\n",
    "**Regression:**\n",
    "$$MSE \\text{ loss }= -\\frac{1}{n}\\sum_{i=1}^n (\\hat{y_i}-\\bar{y_i})^2\\text{. }$$ \n",
    "  - **Reminder:** These aren't the only loss functions, just the most common.\n",
    "\n",
    "What this means is that the loss might be like some function like we see above, where the smallest loss is at the lowest point (minima). However, since every single sample in our dataset will generate a different function, we dont ever really know what the loss functions look like or even is for that matter. We just randomly \"spawn\" on some part of this function, and try to guess where we should go. This means we don't know what our \"true\" loss function looks like. We are blind, which means we want to take a \"step\" in the direction in which we decrease loss. Since the point with the smallest loss means we get the best prediction, the intuition is that **we can change the weights with respect to the change in loss in the negative direction to take a step towards this minima,** until we reach the minima. This is the idea behind backpropagation for gradient descent.\n",
    "\n",
    "If we take the gradient of the loss functions, we get the following values:\n",
    "\n",
    "**Classification:**\n",
    "$$softmax' \\text{ for a single sample } = (p_i-\\hat{y_i})\\text{. }$$\n",
    "**Regression:**\n",
    "$$MSE' \\text{ for a single sample }= \\hat{y_i}-\\bar{y_i}\\text{. }$$\n",
    "  - If you want to see how these are derived, click [here](####Statistical-Likelihoods-and-Derivatives-of-Loss-Functions).\n",
    "\n",
    "the following is a key for all of the variables:\n",
    "  - $p_i$ is the softmax function\n",
    "  - $\\hat{y_i}$ is the true value that we are trying to predict for the label $i$ in our dataset.\n",
    "  - $\\bar{y_i}$ is the value we predicted with our model\n",
    "  - $x_i$ are the values we get from the last layer.\n",
    "  - $\\frac{1}{n}\\sum_{i=1}^n$ means the \"mean\" of the values.\n",
    "\n",
    "If you look closely, the gradients of the loss quantify how \"far\" our prediction was from the actual values. By changing all the weights in our matrix, subtracting the gradients of the weights with respect to the loss for every single weight, we do a single step of backpropagation. If we do this backpropagation step until we reach the loss minimum, we will successfully perform gradient descent, our model will eventually \"converge\" to the local minima, and be able to predict the values we want!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation: The Math Behind Each Backwards Step\n",
    "\n",
    "While in theory backpropagation might make sense, this is generally one of the hardest concepts to grasp the neural network. This is because backpropagation compounds on the fact that in order to calulate the gradient of the weights, (which is a weight matrix, as we had shown in forward pass), we have to chain the derivatives of the loss with the activations and pre-activations to be able to get the corresponding weight gradient. This means we have to calculate the gradient of the weights and biases for every layer, and tune them individually. For example, let's look at the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 2, 4, 3,3],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={},\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a disclaimer, I have no idea how this was derived. I only know the formulas. If we want to calculate the gradients of all of the weights with respect to the loss for our example network, it would look something like the following:\n",
    "\n",
    "$$\\nabla_{W^{(3)}} = \\frac{\\partial L}{\\partial z^{(3)}}\\cdot\\frac{\\partial z^{(3)}}{\\partial W^{(3)}}$$\n",
    "$$\\nabla_{b^{(3)}} = \\frac{\\partial L}{\\partial z^{(3)}}$$\n",
    "$$\\nabla_{W^{(2)}} = \\frac{\\partial L}{\\partial z^{(3)}}\\cdot\\frac{\\partial z^{(3)}}{\\partial a^{(2)}}\\cdot\\frac{\\partial a^{(2)}}{\\partial z^{(2)}}\\cdot\\frac{\\partial z^{(2)}}{\\partial W^{(2)}}$$\n",
    "$$\\nabla_{b^{(2)}} = \\frac{\\partial L}{\\partial z^{(3)}}\\cdot\\frac{\\partial z^{(3)}}{\\partial a^{(2)}}\\cdot\\frac{\\partial a^{(2)}}{\\partial z^{(2)}}$$\n",
    "$$\\nabla_{W^{(1)}} = \\frac{\\partial L}{\\partial z^{(3)}}\\cdot\\frac{\\partial z^{(3)}}{\\partial a^{(2)}}\\cdot\\frac{\\partial a^{(2)}}{\\partial z^{(2)}}\\cdot\\frac{\\partial z^{(2)}}{\\partial a^{(1)}}\\cdot\\frac{\\partial a^{(1)}}{\\partial z^{(1)}}\\cdot\\frac{\\partial z^{(1)}}{\\partial W^{(1)}}$$\n",
    "$$\\nabla_{b^{(1)}} = \\frac{\\partial L}{\\partial z^{(3)}}\\cdot\\frac{\\partial z^{(3)}}{\\partial a^{(2)}}\\cdot\\frac{\\partial a^{(2)}}{\\partial z^{(2)}}\\cdot\\frac{\\partial z^{(2)}}{\\partial a^{(1)}}\\cdot\\frac{\\partial a^{(1)}}{\\partial z^{(1)}}$$\n",
    "This essentially means you are calulating the loss of the current layer by looking at the loss from the next layer and multiplying it by the derivatives of the previous layer's activated values and unactivated values.\n",
    "\n",
    "**Tip:** If you are coding this yourself, it's a good idea to save the pre-activated ($z$) and activated ($a$) values seperately. \n",
    "\n",
    "Where\n",
    "  - $\\large\\frac{\\partial L}{\\partial z^{(i)}}$ is the direction of change needed to adjust the third layer's pre-activated z for the propagation of the loss\n",
    "  - $\\large\\frac{\\partial z^{(i)}}{\\partial a^{(i-1)}}$  is the change needed to adjust the previous layer's node (activated value) for the propogation of the loss\n",
    "  - $\\large\\frac{\\partial a^{(i)}}{\\partial z^{(i)}}$ is the change needed to adjust the current layer's value based on the activation function. Since the activation function is a function itself, that's how the chain rule ends up growing in length the more you go through layers.\n",
    "\n",
    "\n",
    "It's a little hard to visualize these derivative changes, so let's try and work through the math. I know this is pretty complex, but notice this pattern here:\n",
    "  - We only need to compute the derivative with respect to the weight we care about\n",
    "  - Otherwise, its just some combination of $a$ (the node output for that layer), and $z$ (the preactivated node output for that layer-think before we apply our activation function) propagated from layers previous. This means that once we compute all of the other previous values, we just have to compute the next one in succession!\n",
    "  - You also already compute the gradient for the bias of each layer before finding the gradient of the weights\n",
    "\n",
    "Knowing all of this, **it's possible to set up a recursive formula to simplify it, like you would a loop in a coding program!** This part of the program will be pretty math-intensive, so feel free to go back and reread it. I will also have examples of me using backpropagation in examples, so you can get a grasp of it. IF you want even more practice, I personally learned backpropagation by having ChatGPT generate me small feed forward and backpropagation problems for both categorical and regression tasks that I could do by hand, with about 1-2 hidden layers each. Practice makes perfect.\n",
    "\n",
    "\n",
    "#### What the first $\\delta$ is:\n",
    "For our purposes, $\\delta$ just means calculated loss, and likewise $\\delta^{(\\ell)}$ is the loss for that specific layer. The final layer, $\\delta^{(\\ell)}$ is just our derivative loss values, or $\\large\\frac{\\partial L}{\\partial z^{(3)}}$. Do you remember the $(p_i-\\hat{y_i})$ from above? For a hypothetical example, we have 3 categorical variables. Let's say we're trying to predict a number being either 1, 2, or 3, just to give meaning to the classification head, and let's say for the particular example we give it the true value is a 2. This means our $\\hat{y_i}=$\n",
    "$$\n",
    "\\left( \\begin{array}{cccc}\n",
    "0\\\\[0.5em]\n",
    "1\\\\[0.5em]\n",
    "0\\\\[0.5em]\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "then let's assume our model predicts the following values for each category with the softmax:\n",
    "\n",
    "$$\n",
    "\\left( \\begin{array}{cccc}\n",
    ".39\\\\[0.5em]\n",
    ".33\\\\[0.5em]\n",
    ".28\\\\[0.5em]\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "then the loss with respect to the last layer for our hypthetical values will be\n",
    "\n",
    "$$\n",
    "\\delta^{(\\ell)} = \n",
    "\\left( \\begin{array}{cccc}\n",
    ".39\\\\[0.5em]\n",
    ".33\\\\[0.5em]\n",
    ".28\\\\[0.5em]\n",
    "\\end{array}\\right) -\n",
    "\\left( \\begin{array}{cccc}\n",
    "0\\\\[0.5em]\n",
    "1\\\\[0.5em]\n",
    "0\\\\[0.5em]\n",
    "\\end{array}\\right)  \n",
    " = \n",
    "\\left( \\begin{array}{cccc}\n",
    "-.61\\\\[0.5em]\n",
    ".67\\\\[0.5em]\n",
    "-.28\\\\[0.5em]\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "You can think of it like we are trying to lower the values that are wrong and increase the values that are right! I will give an example of regression for this at the bottom of the document.\n",
    "\n",
    "\n",
    "#### Deriving the update rule\n",
    "\n",
    "The most important thing to deriving the update rule is noticing patterns. We can see that any loss for the next layer is simply the loss for the previous layer, with the following values tacked on: $$\\frac{\\partial z^{(3)}}{\\partial a^{(2)}}\\cdot\\frac{\\partial a^{(2)}}{\\partial z^{(2)}}$$\n",
    "Then that means we can let $\\delta^{(\\ell)}$ be the loss of the function per layer. If we look at the pattern I showed you we can build a rule: $\\large\\delta^{(\\ell)}\\cdot\\frac{\\partial z^{(\\ell)}}{\\partial a^{(\\ell-1)}}\\cdot\\frac{\\partial a^{(\\ell-1)}}{\\partial z^{(\\ell-1)}}$.\n",
    "\n",
    "\n",
    "To calculate the loss $\\delta^{(\\ell-1)}$. We know that $z^{(\\ell)} = W^{(\\ell)}\\cdot a^{(\\ell-1)} + b^{(\\ell)}$, from our forward pass, before activation. We can start from here, because we already computed the derivative of the final layer doing ($p_i-y_i$). This means that taking the derivative of this function via the chain rule would therefore look something like this:\n",
    "$$\\frac{\\partial z^{(\\ell)}}{\\partial a^{(\\ell-1)}}[z^{(\\ell)} = W^{(\\ell)}\\cdot a^{(\\ell-1)} + b^{(\\ell)}] = W^{(\\ell)}$$\n",
    "since the bias term just goes away. However for our second derivative $\\large\\frac{\\partial a^{(\\ell-1)}}{\\partial z^{(\\ell-1)}}$, we use the function $a^{(\\ell-1)} = f(W^{(\\ell-1)}\\cdot a^{(\\ell-2)} + b^{(\\ell-1)})$. Notice how this is functionally equivalent to $a^{(\\ell-1)} = f(z^{(\\ell-1)})$. Then\n",
    "$$\\frac{\\partial a^{(\\ell-1)}}{\\partial z^{(\\ell-1)}}[f(z^{(\\ell-1)})] = f'(z^{(\\ell-1)})\\cdot 1 = f'(z^{(\\ell-1)})$$\n",
    "where $f'(x)$ is the derivative of the activation function for the layer $\\ell-1$.\n",
    "\n",
    "Notice that this z vector is a vector, not a matrix corresponding to the size of the nodes. This means when we finally construct our update rule, we need to do element-wise multiplication, via the hadamard product. \n",
    "\n",
    "#### Mini-lesson on Hadamard Product\n",
    "You can only multiply these 2 matrices/vectors if they are the same dimensions, and every element in one matrix A $a_{i\\text{ , } j}$ will be multiplied by its corresponding coordinates in matrix B $b_{i\\text{ , } j}$ to get a matrix AB = $a_{i\\text{ , } j}*b_{i\\text{ , } j}$. For example, let's say I have 2 matrices\n",
    "\n",
    "$$\n",
    "A = \\left( \\begin{array}{cccc}\n",
    "1 & 2 & 3\\\\[0.5em]\n",
    "4 & 5 & 6\\\\[0.5em]\n",
    "7 & 8 & 9\\\\[0.5em]\n",
    "\\end{array}\\right) \\text{ and }\n",
    "B = \\left( \\begin{array}{cccc}\n",
    "1 & 2 & 3\\\\[0.5em]\n",
    "4 & 5 & 6\\\\[0.5em]\n",
    "7 & 8 & 9\\\\[0.5em]\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "Their hadamard product (element-wise matrix multiplication) would be \n",
    "\n",
    "$$\n",
    "\\left( \\begin{array}{cccc}\n",
    "1 & 2 & 3\\\\[0.5em]\n",
    "4 & 5 & 6\\\\[0.5em]\n",
    "7 & 8 & 9\\\\[0.5em]\n",
    "\\end{array}\\right)\\odot\n",
    "\\left( \\begin{array}{cccc}\n",
    "1 & 2 & 3\\\\[0.5em]\n",
    "4 & 5 & 6\\\\[0.5em]\n",
    "7 & 8 & 9\\\\[0.5em]\n",
    "\\end{array}\\right) = \n",
    "\\left( \\begin{array}{cccc}\n",
    "1 & 4 & 9\\\\[0.5em]\n",
    "16 & 25 & 36\\\\[0.5em]\n",
    "49 & 64 & 81\\\\[0.5em]\n",
    "\\end{array}\\right) = AB\n",
    "$$\n",
    "\n",
    "normal matrix multiplication on the other hand would yield\n",
    "$$\n",
    "\\left( \\begin{array}{cccc}\n",
    "1 & 2 & 3\\\\[0.5em]\n",
    "4 & 5 & 6\\\\[0.5em]\n",
    "7 & 8 & 9\\\\[0.5em]\n",
    "\\end{array}\\right) \\text{X}\n",
    "\\left( \\begin{array}{cccc}\n",
    "1 & 2 & 3\\\\[0.5em]\n",
    "4 & 5 & 6\\\\[0.5em]\n",
    "7 & 8 & 9\\\\[0.5em]\n",
    "\\end{array}\\right) = \n",
    "\\left( \\begin{array}{cccc}\n",
    "30 & 36 & 42\\\\[0.5em]\n",
    "66 & 81 & 96\\\\[0.5em]\n",
    "102 & 126 & 150\\\\[0.5em]\n",
    "\\end{array}\\right) = AB\n",
    "$$\n",
    "\n",
    "#### Back to Propagation\n",
    "with this now in mind, we put our derivations together to get our new update rule for each layer's loss:\n",
    "\n",
    "$$\\large\\delta^{(\\ell-1)} = \\delta^{(\\ell)}\\cdot\\frac{\\partial z^{(\\ell)}}{\\partial a^{(\\ell-1)}}\\cdot\\frac{\\partial a^{(\\ell-1)}}{\\partial z^{(\\ell-1)}} = W^{(\\ell)T}\\delta^{(\\ell)} \\odot f'(z^{(\\ell-1)})\n",
    "$$\n",
    "\n",
    "or less confusingly, \n",
    "$$\\Large\\delta^{(\\ell-1)} = W^{(\\ell)T}\\delta^{(\\ell)} \\odot f'(z^{(\\ell-1)}).$$\n",
    "This is the loss for every layer! As a reminder:\n",
    "  - $(\\ell)$ is the layer\n",
    "  - $\\large \\delta^{(\\ell-1)}$ is the loss for the layer $\\ell-1$ \n",
    "  - $\\large W^{(\\ell)}$ is the weight matrix for layer $\\ell$\n",
    "  - $\\large \\delta^{(\\ell)}$ is the loss for the layer $\\ell$\n",
    "  - $\\large z^{(\\ell-1)}$ is the values calculated for the node BEFORE it is sent through the activation function for that layer\n",
    "  - $\\large f(z^{(\\ell)})$ is the activation function for the layer corresponding to the layer of it's z value\n",
    "  - $\\large f'(x)$ is the derivative of the activation function\n",
    "  - $\\large f'(z^{(\\ell-1)})$ are the preactivated nodes from the $\\ell-1$ layer, **put through the DERIVATIVE of their activation.** <- This is common source of confusion.\n",
    "  - $\\odot$ is the hadamard product, aka element-wise multiplication (**DIFFERENT FROM MATRIX MULTIPLICATION**)\n",
    "  - $^T$ is transpose, where we switch the rows to be the columns of a matrix, and the columns to be the rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the Gradient of the bias and Weight Matrices\n",
    "The most important part about making update rules is looking for patterns. Look at the following: What do you notice?\n",
    "\n",
    "##### Bias\n",
    "Let's look at our previous examples for bias derivations:\n",
    "$$\\nabla_{b^{(3)}} = \\frac{\\partial L}{\\partial z^{(3)}}$$\n",
    "$$\\nabla_{b^{(2)}} = \\frac{\\partial L}{\\partial z^{(3)}}\\cdot\\frac{\\partial z^{(3)}}{\\partial a^{(2)}}\\cdot\\frac{\\partial a^{(2)}}{\\partial z^{(2)}}$$\n",
    "$$\\nabla_{b^{(1)}} = \\frac{\\partial L}{\\partial z^{(3)}}\\cdot\\frac{\\partial z^{(3)}}{\\partial a^{(2)}}\\cdot\\frac{\\partial a^{(2)}}{\\partial z^{(2)}}\\cdot\\frac{\\partial z^{(2)}}{\\partial a^{(1)}}\\cdot\\frac{\\partial a^{(1)}}{\\partial z^{(1)}}$$\n",
    "\n",
    "Did you notice that this is exactly the loss of every single layer? This means that for our update rule, once we find our the loss we find our bias! in other words\n",
    "$$\\Large\\delta^{(\\ell)}=\\nabla_{b^{(\\ell)}}$$\n",
    "\n",
    "##### Weights\n",
    "for $\\large\\nabla_{W^{(\\ell)}}$, we notice that the only difference is now we tack on $\\large\\frac{\\partial z^{(3)}}{\\partial W^{(3)}}$ or \n",
    "$$\\nabla_{W^{(3)}} = \\frac{\\partial L}{\\partial z^{(3)}}\\cdot\\frac{\\partial z^{(\\ell)}}{\\partial W^{(\\ell)}}$$\n",
    "$$\\nabla_{W^{(2)}} = \\frac{\\partial L}{\\partial z^{(3)}}\\cdot\\frac{\\partial z^{(3)}}{\\partial a^{(2)}}\\cdot\\frac{\\partial a^{(2)}}{\\partial z^{(2)}}\\cdot\\frac{\\partial z^{(2)}}{\\partial W^{(2)}}$$\n",
    "$$\\nabla_{W^{(1)}} = \\frac{\\partial L}{\\partial z^{(3)}}\\cdot\\frac{\\partial z^{(3)}}{\\partial a^{(2)}}\\cdot\\frac{\\partial a^{(2)}}{\\partial z^{(2)}}\\cdot\\frac{\\partial z^{(2)}}{\\partial a^{(1)}}\\cdot\\frac{\\partial a^{(1)}}{\\partial z^{(1)}}\\cdot\\frac{\\partial z^{(1)}}{\\partial W^{(1)}}$$\n",
    "\n",
    "all of these are essentially loss multiplied by the derivative of the weight matrix (gradient). So then we can build the following rule, by looking at the patterns:\n",
    "$$\\large\\nabla_{W^{(\\ell)}} = \\delta^{(\\ell)}\\cdot\\frac{\\partial z^{(\\ell)}}{\\partial W^{(\\ell)}}$$\n",
    "if we deconstruct this derivative, the top is the function $z^{(\\ell)}$. We then can grab the function corresponding: $z^{(\\ell)} = W^{(\\ell)}\\cdot a^{(\\ell-1)} + b^{(\\ell)}$. Then \n",
    "$$\\frac{\\partial z^{(\\ell)}}{\\partial W^{(\\ell)}}[W^{(\\ell)}\\cdot a^{(\\ell-1)} + b^{(\\ell)}] =  a^{(\\ell-1)}$$\n",
    "Notice that $\\delta{(\\ell)}$ and $a^{(\\ell-1)}$ do not match dimension, nor will they create a matrix of the same dimensions of the weight matrix. They are both dimensions $\\large n^{(\\ell)}\\text{x}1$ and $\\large n^{(\\ell-1)}\\text{x}1$ respectively, where $n$ is the number of nodes in the layer. IF we want to make it the size of the weight matrix, we do $\\large a^{(\\ell-1)T}$ so we get dimensions $\\large n^{(\\ell)}\\text{x}1$ and $\\large 1\\text{x}n^{(\\ell-1)}$ for the matrix outer product, which matches the dimensions of the weight matrix. We can now find out what the update rule for the gradient of a weight matrix of any given layer!\n",
    "$$\\Large\\nabla_{W^{(\\ell)}}=\\delta^{(\\ell)}\\cdot a^{(\\ell-1)T}$$\n",
    "\n",
    "### Final Update Rules\n",
    "Based on the following update rules, we have deduced recursively the update rules for any given layer, and they are as follows:\n",
    "\n",
    "$$\\Large\\text{The first }\\delta^{(\\ell)} = (p_i-\\hat{y_i}) \\text{ for classification, or } (\\hat{y_i}-\\bar{y_i}) \\text{ for regression.}$$\n",
    "$$\\Large\\nabla_{W^{(\\ell)}}=\\delta^{(\\ell)} a^{(\\ell-1)T}$$\n",
    "$$\\Large\\nabla_{b^{(\\ell)}} = \\delta^{(\\ell)}$$\n",
    "$$\\Large\\delta^{(\\ell-1)} = W^{(\\ell)T}\\delta^{(\\ell)} \\odot f'(z^{(\\ell-1)}).$$\n",
    "\n",
    "Where:\n",
    "  - $\\hat{y_i}$ is the predicted value generated by your network's forward pass for any given category, for a certain sample.\n",
    "  - $\\bar{y_i}$ is the actual value/label given to you for any given category, for a certain sample. This will be 0/1 for classification and some real number for regression.\n",
    "  - $p_i$ is the softmax function.\n",
    "  - $(\\ell)$ is the layer\n",
    "  - $\\large W^{(\\ell)}$ is the weight matrix for layer $\\ell$\n",
    "  - $\\large \\delta^{(\\ell)}$ is the loss for the layer $\\ell$\n",
    "  - Likewise, $\\large \\delta^{(\\ell-1)}$ is the loss for the layer $\\ell-1$ \n",
    "  - $\\large z^{(\\ell-1)}$ is the values calculated for the node BEFORE it is sent through the activation function for that layer\n",
    "  - $\\large f(z^{(\\ell)})$ is the activation function for the layer corresponding to the layer of it's preactivated nodes\n",
    "  - $\\large f'(x)$ is the derivative of the activation function\n",
    "  - $\\large f'(z^{(\\ell-1)})$ are the preactivated nodes from the $\\ell-1$ layer, **put through the DERIVATIVE of their activation.** <- This is common source of confusion.\n",
    "  - $\\odot$ is the hadamard product, aka element-wise multiplication (**DIFFERENT FROM MATRIX MULTIPLICATION**)\n",
    "  - $^T$ is transpose, where we switch the rows to be the columns of a matrix, and the columns to be the rows.\n",
    "  - $\\large\\delta^{(\\ell)}\\cdot a^{(\\ell-1)T}$ is an outer product\n",
    "  - $\\large a^{(\\ell)} = f(W^{(\\ell)}\\cdot a^{(\\ell-1)} + b^{(\\ell)}) = f(z^{(\\ell)})$\n",
    "  - $\\large z^{(\\ell)} = W^{(\\ell)}\\cdot a^{(\\ell-1)} + b^{(\\ell)}$\n",
    "\n",
    "This is definitely a lot of information, so make sure to come back to this a couple of times to be able to get it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight updates (motivations of gradient descent)\n",
    "\n",
    "Now that we are able to derive the gradients of the weights, we can take a step in the direction of these gradients. Naively, we can do this by subtracting the gradients from the current weights, and likewise with the biases:\n",
    "$$W^{(\\ell)}_{new} = W^{(\\ell)} - \\nabla W^{(\\ell)}$$\n",
    "$$b^{(\\ell)}_{new} = b^{(\\ell)} - \\nabla b^{(\\ell)}$$\n",
    "\n",
    "This basic idea is how gradient descent works, however there is an important caveat: We might take too big of a step. Let's visualize how a parameter space for a loss function MIGHT look. Run the following simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = GradientDescentSimulator(learning_rate=50, title=\"Gradient Descent With no Learning Rate\", max_iter=100)\n",
    "sim.fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see what happens? The gradient tells us to move quickly where it's steep, and as a result, we \"overshoot\" our minimum point of loss. We keep moving back and forth, and we will never reach the best minima.\n",
    "\n",
    "Here's an analogy: Think you are holding a basketball in a dense fog, so dense that you can't see anything. This is basketball your neural network. Your goal is to throw the basketball into the hoop, but you obviously don't know where it is because you can't see You have some information telling you which direction to throw the basketball and it tells you how hard to throw the ball. Every time you throw the ball, you're automatically teleported to the ball, so you don't get to walk over the landscape to see if you can guess where to shoot. For some reason, the information telling you to throw it harder and harder when you're close to the goal. As a result, you're never able to get the ball into the hoop. You don't have all day!\n",
    "\n",
    "We can see that in our simulation, the curve gets steeper the closer we get to the local minimum. As a result, the gradient tells us to throw our ball REALLY hard, because the negative gradient is steep, like we saw in the example above. So how do we fix this?\n",
    "\n",
    "### Our first Hyperparameter: $\\eta$ (learning rate) and the Gradient Descent Algorithm\n",
    "\n",
    "We can add some small constant $\\eta$ to the negative gradients to \"dampen\" their effects on the weights. This will effectively make us \"toss\" the basketball a bunch of times, so that we inch towards the goal. This kind of makes more sense, because we can't see! The classic gradient descent algorithm can therefore be written as such: \n",
    "\n",
    "$$\\large W^{(\\ell)}_{new} = W^{(\\ell)} - \\eta\\nabla W^{(\\ell)}$$\n",
    "$$\\large b^{(\\ell)}_{new} = b^{(\\ell)} - \\eta\\nabla b^{(\\ell)}$$\n",
    "\n",
    "where\n",
    " - $\\eta$ is the learning rate. This is usually some small number, custom to every neural network problem! (You need to figure out the best one yourself)\n",
    " - $\\nabla b^{(\\ell)}$ is the gradient of the biases for that layer $\\ell$\n",
    " - $\\nabla W^{(\\ell)}$ is the gradient of the Weight Matrix for that layer $\\ell$\n",
    " - $W^{(\\ell)}$ is the weight matrix for layer $\\ell$\n",
    " - $b^{(\\ell)}$ is the biases for layer $\\ell$\n",
    " - $W^{(\\ell)}_{new}$ is the updated weight matrix for layer $\\ell$\n",
    " - $b^{(\\ell)}_{new}$ is the updated biases matrix for layer $\\ell$\n",
    "\n",
    "Let's see what happens when we add this constant to our simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = GradientDescentSimulator(learning_rate=10, title=\"Gradient Descent With Good Learning Rate\",max_iter=100)\n",
    "sim.fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we converge perfectly! We now have all the tools to go through a full backpropagation example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation Example\n",
    "\n",
    " In the meantime, let's use our new update rules to apply backpropagation to our synthetic model we had defined previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 2, 4, 3,3],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={},\n",
    "    special_inter_layer_arrow_color=\"blue\",\n",
    "    special_inter_layer_arrow_target_layer=3,\n",
    "    special_inter_layer_arrow_offset=\"node\",\n",
    "    bias=True\n",
    "    \n",
    ")\n",
    "\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using ReLU, as this activation is a special case in terms of activation function derivatives, and is also the most commonly used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 3\n",
    "\n",
    "Let's recall our toolbox of update rules:\n",
    "$$\\text{The first }\\delta^{(\\ell)} = (p_i-\\hat{y_i}) \\text{ for classification, or } (\\hat{y_i}-\\bar{y_i}) \\text{ for regression.}$$\n",
    "$$\\nabla_{W^{(\\ell)}}=\\delta^{(\\ell)} a^{(\\ell-1)T}$$\n",
    "$$\\nabla_{b^{(\\ell)}} = \\delta^{(\\ell)}$$\n",
    "$$\\delta^{(\\ell-1)} = W^{(\\ell)T}\\delta^{(\\ell)} \\odot f'(z^{(\\ell-1)})$$\n",
    "\n",
    "#### Step 1: Calculate initial loss\n",
    "Because we have specified that this is a classification problem, we know:\n",
    "$$\\delta^{(3)} = \n",
    "\\left( \\begin{array}{cccc}\n",
    "p_1 - y_1 \\\\[0.5em]\n",
    "p_2 - y_2 \\\\[0.5em]\n",
    "p_3 - y_3\\\\[0.5em]\n",
    "\\end{array}\\right)$$\n",
    "\n",
    "#### Step 2: Calculate the weight and bias gradients\n",
    "\n",
    "We are now at this point on the graph:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[2, 2, 4, 3,3],\n",
    "    label_arrows=False,\n",
    "    arrow_label_overrides={},\n",
    "    special_inter_layer_arrow_color=\"blue\",\n",
    "    special_inter_layer_arrow_target_layer=3,\n",
    "    special_inter_layer_arrow_offset=\"layer\",\n",
    "    bias=True\n",
    "    \n",
    ")\n",
    "\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate our weights with the update rule $\\nabla_{W^{(\\ell)}}=\\delta^{(\\ell)} a^{(\\ell-1)T}$.\n",
    "\n",
    "$$\\Large\\nabla_{W^{(\\ell)}} = \\delta^{(3)} a^{(2)T}\\normalsize = \n",
    "\\left( \\begin{array}{cccc}\n",
    "p_1 - y_1 \\\\[0.5em]\n",
    "p_2 - y_2 \\\\[0.5em]\n",
    "p_3 - y_3\\\\[0.5em]\n",
    "\\end{array}\\right)\\cdot\n",
    "\\left( \\begin{array}{cccc}\n",
    "\\text{Node 1} \\\\[0.5em]\n",
    "\\text{Node 2} \\\\[0.5em]\n",
    "\\text{Node 3}\\\\[0.5em]\n",
    "\\text{Node 4}\\\\[0.5em]\n",
    "\\end{array}\\right)^T =\n",
    "\\left( \\begin{array}{cccc}\n",
    "p_1 - y_1 \\\\[0.5em]\n",
    "p_2 - y_2 \\\\[0.5em]\n",
    "p_3 - y_3\\\\[0.5em]\n",
    "\\end{array}\\right)\\cdot\n",
    "\\left( \\begin{array}{cccc}\n",
    "\\text{Node 1} & \\text{Node 2}& \\text{Node 3}& \\text{Node 4}\\\\[0.5em]\n",
    "\\end{array}\\right) =\n",
    "\\left( \\begin{array}{cccc}\n",
    "(p_1 - y_1)\\cdot\\text{Node 1} & (p_1 - y_1)\\cdot\\text{Node 2} & (p_1 - y_1)\\cdot\\text{Node 3} & (p_1 - y_1)\\cdot\\text{Node 4} \\\\[0.5em]\n",
    "(p_2 - y_2)\\cdot\\text{Node 1} & (p_2 - y_2)\\cdot\\text{Node 2} & (p_2 - y_2)\\cdot\\text{Node 3} & (p_2 - y_2)\\cdot\\text{Node 4} \\\\[0.5em]\n",
    "(p_3 - y_3)\\cdot\\text{Node 1} & (p_3 - y_3)\\cdot\\text{Node 2} & (p_3 - y_3)\\cdot\\text{Node 3} & (p_3 - y_3)\\cdot\\text{Node 4}\n",
    "\\end{array}\\right) \n",
    "$$\n",
    "\n",
    "We calculate our bias to be via the update rule:\n",
    "\n",
    "$$\n",
    "\\Large\\nabla_{b^{(3)}} = \\delta^{(3)} \\normalsize= \n",
    "\\left( \\begin{array}{cccc}\n",
    "p_1 - y_1 \\\\[0.5em]\n",
    "p_2 - y_2 \\\\[0.5em]\n",
    "p_3 - y_3\\\\[0.5em]\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "#### Step 3: Perform Gradient descent:\n",
    "$$\\large W^{(3)}_{new} = W^{(3)} - \\eta\\nabla W^{(3)}$$\n",
    "$$\\Large W^{(3)} \\normalsize= \\left( \\begin{array}{cccc}\n",
    "w_{1,1}^{(3)}& w_{1,2}^{(3)} & w_{1,3}^{(3)} & w_{1,4}^{(3)}\\\\[0.5em]\n",
    "w_{2,1}^{(3)}& w_{2,2}^{(3)} & w_{2,3}^{(3)} & w_{2,4}^{(3)}\\\\[0.5em]\n",
    "w_{3,1}^{(3)}& w_{3,2}^{(3)} & w_{3,3}^{(3)} & w_{3,4}^{(3)}\\\\[0.5em]\n",
    "\\end{array}\\right) $$\n",
    "$$\\large\\nabla W^{(3)} \\normalsize = \n",
    "\\left( \\begin{array}{cccc}\n",
    "(p_1 - y_1)\\cdot\\text{Node 1} & (p_1 - y_1)\\cdot\\text{Node 2} & (p_1 - y_1)\\cdot\\text{Node 3} & (p_1 - y_1)\\cdot\\text{Node 4} \\\\[0.5em]\n",
    "(p_2 - y_2)\\cdot\\text{Node 1} & (p_2 - y_2)\\cdot\\text{Node 2} & (p_2 - y_2)\\cdot\\text{Node 3} & (p_2 - y_2)\\cdot\\text{Node 4} \\\\[0.5em]\n",
    "(p_3 - y_3)\\cdot\\text{Node 1} & (p_3 - y_3)\\cdot\\text{Node 2} & (p_3 - y_3)\\cdot\\text{Node 3} & (p_3 - y_3)\\cdot\\text{Node 4}\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "$$\\large W^{(3)}_{new} = \\left( \\begin{array}{cccc}\n",
    "w_{1,1}^{(3)}& w_{1,2}^{(3)} & w_{1,3}^{(3)} & w_{1,4}^{(3)}\\\\[0.5em]\n",
    "w_{2,1}^{(3)}& w_{2,2}^{(3)} & w_{2,3}^{(3)} & w_{2,4}^{(3)}\\\\[0.5em]\n",
    "w_{3,1}^{(3)}& w_{3,2}^{(3)} & w_{3,3}^{(3)} & w_{3,4}^{(3)}\\\\[0.5em]\n",
    "\\end{array}\\right) - \\eta\\left( \\begin{array}{cccc}\n",
    "(p_1 - y_1)\\cdot\\text{Node 1} & (p_1 - y_1)\\cdot\\text{Node 2} & (p_1 - y_1)\\cdot\\text{Node 3} & (p_1 - y_1)\\cdot\\text{Node 4} \\\\[0.5em]\n",
    "(p_2 - y_2)\\cdot\\text{Node 1} & (p_2 - y_2)\\cdot\\text{Node 2} & (p_2 - y_2)\\cdot\\text{Node 3} & (p_2 - y_2)\\cdot\\text{Node 4} \\\\[0.5em]\n",
    "(p_3 - y_3)\\cdot\\text{Node 1} & (p_3 - y_3)\\cdot\\text{Node 2} & (p_3 - y_3)\\cdot\\text{Node 3} & (p_3 - y_3)\\cdot\\text{Node 4}\n",
    "\\end{array}\\right)$$\n",
    "\n",
    "$$\\large b^{(3)}_{new} = b^{(3)} - \\eta\\nabla b^{(3)}$$\n",
    "$$\\large b^{(3)} \\normalsize = \n",
    "\\left( \\begin{array}{cccc}\n",
    "b_{1}^{(3)}& \\\\[0.5em]\n",
    "b_{2}^{(3)}& \\\\[0.5em]\n",
    "b_{3}^{(3)}& \\\\[0.5em]\n",
    "\\end{array}\\right) \n",
    "$$\n",
    "$$\\large\\nabla b^{(3)}=\\delta^{(3)} \\normalsize\n",
    "\\left( \\begin{array}{cccc}\n",
    "p_1 - y_1 \\\\[0.5em]\n",
    "p_2 - y_2 \\\\[0.5em]\n",
    "p_3 - y_3\\\\[0.5em]\n",
    "\\end{array}\\right)$$\n",
    "$$\\large b^{(3)}_{new}\\normalsize = \n",
    "\\left( \\begin{array}{cccc}\n",
    "b_{1}^{(3)}& \\\\[0.5em]\n",
    "b_{2}^{(3)}& \\\\[0.5em]\n",
    "b_{3}^{(3)}& \\\\[0.5em]\n",
    "\\end{array}\\right) \n",
    "-\\eta\n",
    "\\left( \\begin{array}{cccc}\n",
    "p_1 - y_1 \\\\[0.5em]\n",
    "p_2 - y_2 \\\\[0.5em]\n",
    "p_3 - y_3\\\\[0.5em]\n",
    "\\end{array}\\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Calculate Loss for the New Layer\n",
    "Our update rule is as follows:\n",
    "Do ReLU\n",
    "$\\delta^{(2)} = W^{(3)T}\\delta^{(3)} \\odot f'(z^{(2)})$\n",
    "\n",
    "$$\n",
    "\\left( \\begin{array}{ccc}\n",
    "w_{1,1}^{(3)} & w_{2,1}^{(3)} & w_{3,1}^{(3)} \\\\[0.5em]\n",
    "w_{1,2}^{(3)} & w_{2,2}^{(3)} & w_{3,2}^{(3)} \\\\[0.5em]\n",
    "w_{1,3}^{(3)} & w_{2,3}^{(3)} & w_{3,3}^{(3)} \\\\[0.5em]\n",
    "w_{1,4}^{(3)} & w_{2,4}^{(3)} & w_{3,4}^{(3)}\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left( \\begin{array}{cccc}\n",
    "w_{1,1}^{(3)}& w_{1,2}^{(3)} & w_{1,3}^{(3)} & w_{1,4}^{(3)}\\\\[0.5em]\n",
    "w_{2,1}^{(3)}& w_{2,2}^{(3)} & w_{2,3}^{(3)} & w_{2,4}^{(3)}\\\\[0.5em]\n",
    "w_{3,1}^{(3)}& w_{3,2}^{(3)} & w_{3,3}^{(3)} & w_{3,4}^{(3)}\\\\[0.5em]\n",
    "\\end{array}\\right)^T = $$\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_vis = NeuralNetworkVisualization(batchSize=10, nodes_per_layer=[10,5,4,6,3,5,5],bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot = NeuralNetworkPlot(\n",
    "    nodes_per_layer=[1, 5, 3, 2, 4, 4],\n",
    "    label_arrows=True,\n",
    "    arrow_label_overrides={},  # provide any overrides as needed\n",
    "    special_inter_layer_arrow_target_layer=1,  # will put arrow at x=1-0.5 = 0.5\n",
    "    special_inter_layer_arrow_color=\"red\"\n",
    ")\n",
    "\n",
    "# Display the plot.\n",
    "nn_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Gradient descent / normal gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = GradientDescentSimulator(learning_rate=1, title=\"Gradient Descent With Low Learning Rate\",max_iter=100)\n",
    "sim.fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_multi = MultiMinimaSimulator(learning_rate=5, title=\"Learning Rate that is too High for a Non-convex Space\",camera_distance=1,azim=35,elev=25)\n",
    "sim_multi.fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_multi = MultiMinimaSimulator(learning_rate=1, title=\"Learning Rate that is optimized for the parameter space\",camera_distance=1,azim=135,elev=25)\n",
    "sim_multi.fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_adaptive = MultiMinimaSimulatorAdaptive(\n",
    "    learning_rate=0.7,\n",
    "    title=\"Optimizer Comparisons\",\n",
    "    azim=50,  \n",
    "    elev=35,   \n",
    "    r_cam=1  \n",
    ")\n",
    "\n",
    "sim_adaptive.fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivatives for the activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Likelihoods and Derivatives of Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax reduction into sigmoid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
